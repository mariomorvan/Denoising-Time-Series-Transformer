{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl \n",
    "\n",
    "GPUS = int(torch.cuda.is_available())\n",
    "# torch.cuda.empty_cache() \n",
    "def print_cuda_summary():\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    f = r-a  # free inside reserved\n",
    "\n",
    "    print(\"torch.cuda.get_device_properties(0).total_memory %fGB\"%(t/1024/1024/1024))\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"Free (res - alloc) %fGB\"%(f/1024/1024/1024))\n",
    "\n",
    "if GPUS:\n",
    "    print_cuda_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebda696",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 1000\n",
    "val_ratio = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "seed = 0\n",
    "standardise_axes = (0, 1)  # per sample standardisation\n",
    "\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "\n",
    "if num_workers > 0:\n",
    "    import cv2\n",
    "    cv2.setNumThreads(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8b2f6",
   "metadata": {},
   "source": [
    "### TESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ffacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPUS:\n",
    "    path = \"/state/partition1/mmorvan/data/TESS/lightcurves/0001\"\n",
    "else:\n",
    "    path = \"/Users/mario/data/TESS/lightcurves/0027\"\n",
    "\n",
    "train_path = os.path.join(path, 'processed_train')\n",
    "test_path = os.path.join(path, 'processed_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split generation\n",
    "# import os\n",
    "# from datasets import TessDataset\n",
    "\n",
    "# test_ratio = 0.2\n",
    "    \n",
    "# dataset = TessDataset(path, \n",
    "#                       processed=True, \n",
    "#                       save=False\n",
    "#                       )\n",
    "\n",
    "# #dataset.n_dim = 1\n",
    "# # TRAIN/VAL SPLIT\n",
    "# test_size = int(test_ratio * len(dataset))\n",
    "# train_size = len(dataset) - test_size\n",
    "# print(train_size, test_size)\n",
    "# train_dataset, test_dataset = random_split(dataset, \n",
    "#                                           (train_size, test_size),\n",
    "#                                            generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "# for idx in train_dataset.indices:\n",
    "#     dataset.save_item(idx, train_path)\n",
    "# for idx in test_dataset.indices:\n",
    "#     dataset.save_item(idx, test_path)\n",
    "# #train_dataset.indices\n",
    "\n",
    "# %%bash\n",
    "# ls \"/state/partition1/mmorvan/data/TESS/lightcurves/0001/processed_test\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import TessDataset\n",
    "\n",
    "# test_dataset = TessDataset(test_path, load_processed=True)\n",
    "# train_dataset = TessDataset(train_path, load_processed=True)\n",
    "# len(test_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b25ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import TessDataset\n",
    "\n",
    "from transforms import  Compose,StandardScaler, AddGaussianNoise, Mask, FillNans, RandomCrop, DownSample\n",
    "\n",
    "\n",
    "    \n",
    "transform_both_train = Compose([RandomCrop(800, exclude_missing_threshold=0.8),\n",
    "                          DownSample(2),\n",
    "                          Mask(0.3, block_len=None, value=None, exclude_mask=True),\n",
    "                          StandardScaler(dim=0),\n",
    "                          #FillNans(0),\n",
    "                         ])\n",
    "\n",
    "transform_both_test = Compose([RandomCrop(800, exclude_missing_threshold=0.8),\n",
    "                               DownSample(2),\n",
    "#                                Mask(0.3, block_len=None, value=None, exclude_mask=True),\n",
    "                               StandardScaler(dim=0),\n",
    "                          #FillNans(0),\n",
    "                         ])\n",
    "\n",
    "\n",
    "transform = None\n",
    "\n",
    "if GPUS:\n",
    "    path = \"/state/partition1/mmorvan/data/TESS/lightcurves/0001\"\n",
    "else:\n",
    "    path = \"/Users/mario/data/TESS/lightcurves/0027\"\n",
    "\n",
    "dataset = TessDataset(train_path, \n",
    "                      load_processed=True, \n",
    "                      max_samples=max_samples,\n",
    "                      transform=transform,\n",
    "                      transform_both=transform_both_train,\n",
    "                      use_cache=True,\n",
    "                      )\n",
    "test_dataset = TessDataset(test_path, \n",
    "                           load_processed=True, \n",
    "                           transform_both=transform_both_test,\n",
    "                           use_cache=True,\n",
    "                          )\n",
    "\n",
    "\n",
    "#dataset.n_dim = 1\n",
    "# TRAIN/VAL SPLIT\n",
    "val_size = int(val_ratio * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, \n",
    "                                          (train_size, val_size),\n",
    "                                           generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c313bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GPUS:\n",
    "    print_cuda_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, m, meta = dataset[0]\n",
    "\n",
    "plt.plot(x)\n",
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y,m, i in train_loader:\n",
    "#     assert torch.isclose(x,y, equal_nan=True).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20b257",
   "metadata": {},
   "source": [
    "## Noise Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35bfef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from utils import nanstd\n",
    "# X,_,_,_ = next(iter(train_loader))\n",
    "# B, L, D = X.shape\n",
    "\n",
    "\n",
    "# window = 10\n",
    "# n_windows = L // window\n",
    "# X.view(B, n_windows, window).shape\n",
    "\n",
    "# noise = nanstd(X.view(B, n_windows, window), -1, keepdim=True).nanmedian(1, keepdim=True).values\n",
    "\n",
    "# # Samples highlighted by non-white-noise contribution to the variance\n",
    "# plt.figure(figsize=(30,20))\n",
    "# for i in range(len(X)):\n",
    "#     plt.plot(X[i,:,0], alpha=1-noise[i,0,0].item()**1.5, lw=1/noise[i,0,0])\n",
    "# plt.title('Batch highlighted by inverse noise')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Distribution of noise estimates\n",
    "# plt.hist(noise[:,0,0].numpy(), 50)\n",
    "# plt.title('White Noise Level')\n",
    "# plt.show()\n",
    "\n",
    "# # After correction\n",
    "# plt.figure(figsize=(30,20))\n",
    "# plt.plot((X / noise)[:,:,0].T)\n",
    "# plt.show()\n",
    "\n",
    "# # Check of better noise estimate\n",
    "\n",
    "# def rolling_std(x, width=10):\n",
    "#     return pd.Series(x).rolling(width, center=True, min_periods=1).std().values\n",
    "\n",
    "# better_noise = []\n",
    "# for i in range(len(X)):\n",
    "#     better_noise += [np.nanmedian(rolling_std(X[i,:,0].numpy(), width=10))]\n",
    "# plt.scatter(noise, better_noise)\n",
    "\n",
    "# # dataset_temp = TessDataset(train_path)\n",
    "\n",
    "\n",
    "# # x, y, m, i = dataset_temp[np.random.randint(len(dataset_temp))]\n",
    "# # plt.plot((x - np.nanmedian(x))/np.nanmedian(x))\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f33c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.stats import estimate_noise\n",
    "\n",
    "# X,_,_,_ = next(iter(train_loader))\n",
    "\n",
    "# noise = estimate_noise(X, reduce='nanmedian')\n",
    "# # plt.hist(noise[9].flatten().numpy(), 50)\n",
    "\n",
    "# print(torch.isnan(X/noise).sum(), torch.isnan(X).sum())\n",
    "# # plt.plot((X/np.sqrt(noise))[:,:,0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33c950",
   "metadata": {},
   "source": [
    "### Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa64734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DummyDataset\n",
    "\n",
    "# dataset = DummyDataset(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, m, meta = dataset[0]\n",
    "\n",
    "# plt.plot(x)\n",
    "# plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d83b61",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c2e3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ### TEST RUN\n",
    "# lit_model = LitImputer(1, noise_scaling=True)\n",
    "# trainer = pl.Trainer(max_epochs=10, gpus=GPUS)\n",
    "# result = trainer.fit(lit_model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b06e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_model = LitImputer(1, noise_scaling=True)\n",
    "# from utils.stats import estimate_noise\n",
    "# from models.loss import MaskedMSELoss\n",
    "# criterion = MaskedMSELoss()\n",
    "\n",
    "# for X, Y, M, Info in train_loader:\n",
    "#     Y_pred = lit_model(X)\n",
    "#     noise = torch.sqrt(estimate_noise(Y))\n",
    "#     assert not noise.requires_grad\n",
    "#     assert not torch.isclose(noise, torch.zeros_like(noise), equal_nan=True).any()\n",
    "#     noise[torch.isnan(noise)] = 1.\n",
    "\n",
    "#     loss = criterion(Y_pred, Y, M)\n",
    "#     assert not torch.isnan(loss)\n",
    "    \n",
    "#     pred_proxy = Y_pred / noise\n",
    "#     Y_proxy = Y/noise\n",
    "# #     torch.isnan(Y_pred).sum(), torch.isnan(Y).sum(), torch.isnan(pred_proxy).sum(), torch.isnan(Y_proxy).sum()\n",
    "#     assert not torch.isinf(pred_proxy).any()\n",
    "#     loss_scaled = criterion(pred_proxy, Y_proxy, M)\n",
    "    \n",
    "#     assert not torch.isnan(loss_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc15c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TEST volume\n",
    "# from pytorch_lightning.loggers import NeptuneLogger\n",
    "\n",
    "# logger = NeptuneLogger(project=\"denoising-transformer\",\n",
    "#                            name='test')\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# lit_model = LitImputer(n_dim=1, d_model=8, dim_feedforward=16, num_layers=1,\n",
    "# #                        attention='linear', seq_len=400,\n",
    "#                        random_ratio=1, zero_ratio=0., keep_ratio=0.,token_ratio=0, \n",
    "#                        #, token_ratio=0.8, \n",
    "#                        noise_scaling=\"true\",\n",
    "# #                        attention='linear', seq_len=400\n",
    "#                       )\n",
    "\n",
    "# trainer = pl.Trainer(max_epochs=10000, \n",
    "#                      gpus=GPUS,\n",
    "#                      logger=logger,\n",
    "#                      check_val_every_n_epoch=1)\n",
    "\n",
    "# result = trainer.fit(lit_model, \n",
    "#                      train_dataloaders=train_loader,\n",
    "#                      val_dataloaders=val_loader, \n",
    "#                      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd27596",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LitImputer\n",
    "torch.manual_seed(0)\n",
    "if GPUS:\n",
    "    print_cuda_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c686a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitImputer(n_dim=1, d_model=64, dim_feedforward=128, lr=0.001,\n",
    "#                        attention='linear', seq_len=400,\n",
    "                       random_ratio=1, zero_ratio=0., keep_ratio=0.,token_ratio=0, \n",
    "                       train_unit = 'noise'\n",
    "                       #, token_ratio=0.8, \n",
    "                       #noise_scaling=\"true\",\n",
    "#                        attention='linear', seq_len=400\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, M, I = next(iter(train_loader))\n",
    "\n",
    "# X_masked, token_mask = lit_model.apply_mask(X, M)\n",
    "# X_masked[token_mask.bool()] = np.nan\n",
    "# # i = np.random.randint(len(X_masked))\n",
    "# plt.figure(figsize=(12,6))\n",
    "# #plt.scatter(range(400),X[i].detach(), s=50, alpha=0.6)\n",
    "# plt.scatter(range(400), X_masked[i].detach(), s=5, color='red')\n",
    "# plt.fill_between(range(len(M[i])), -3, 3, where=M[i].flatten(), alpha=0.3)\n",
    "# plt.fill_between(range(len(M[i])), -3, 3, where=token_mask[i].flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60401cec",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find . -mindepth 3 -maxdepth 3 -type d -name \"DEN-245\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ckpt_path = \"/home/mmorvan/denoising-ts-transformer/.neptune/Tess-denoising17-02-2022_01-34-35/DEN-167/checkpoints/epoch=382-step=4992.ckpt\"\n",
    "# # ckpt_path = \"./.neptune/Tess-denoising_17-02-2022_02-19-37/DEN-170/checkpoints/epoch=1032-step=15494.ckpt\"\n",
    "# ckpt_path = \"./.neptune/Tess-denoising17-02-2022_11-11-26/DEN-186/checkpoints/epoch=601-step=15062.ckpt\"\n",
    "# ckpt_path = \"./.neptune/Tess-denoising17-02-2022_11-41-36/DEN-189/checkpoints/epoch=636-step=15924.ckpt\"\n",
    "# # ckpt_path = \"./.neptune/tess_denoising/DEN-219/checkpoints/epoch=2999-step=86999.ckpt\"\n",
    "# ckpt_path = './.neptune/tess_denoising/DEN-245/checkpoints/epoch=1382-step=20744.ckpt'\n",
    "# lit_model = lit_model.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe202c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "logger = NeptuneLogger(project=\"denoising-transformer\",\n",
    "                        name='tess_denoising',\n",
    "                       log_model_checkpoints=True,\n",
    "                       tags=[str(len(dataset))+' samples',\n",
    "                             #\"continued_from_den-186\"\n",
    "                             #\"large-training-set\",\n",
    "                             \"train - \" + lit_model.train_unit,\n",
    "                             #\"star-scaled\"\n",
    "                        #      \"Noise2Noise\",\n",
    "                        #      \"Imputation\",\n",
    "                        #      \"cropped-800\",\n",
    "                        #      \"downsampled-2\",\n",
    "                        #      'linformer'\n",
    "                             #\"replaced_normal\",\n",
    "                             #\"Crop-400\", \n",
    "#                              f\"patch-{patch_size}\",\n",
    "#                              \"TPT\"\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644d0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pytorch_lightning import seed_everything\n",
    "# seed_everything(1)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10000, \n",
    "                     logger=logger, \n",
    "                     gpus=GPUS,\n",
    "                     check_val_every_n_epoch=1)\n",
    "\n",
    "result = trainer.fit(lit_model, \n",
    "                     train_dataloaders=train_loader,\n",
    "                     val_dataloaders=val_loader, \n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit(lit_model, \n",
    "                     train_dataloaders=train_loader,\n",
    "                     val_dataloaders=val_loader, \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc205fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.test(lit_model, \n",
    "             dataloaders=test_loader\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plt.figure(figsize=(13,6))\n",
    "# plt.scatter(range(len(X[i])), X[i,:,j], label='input', color='blue', s=3, alpha=0.4)\n",
    "\n",
    "# plt.plot(Y[i,:,j], label='target', color='green')\n",
    "\n",
    "# plt.plot(pred.cpu().detach()[i,:,j], label='prediction', color='red')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f083b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.stats import estimate_noise\n",
    "lit_model.eval().cuda()\n",
    "with torch.no_grad():\n",
    "    X, Y, M, I = next(iter(train_loader))\n",
    "    Y_pred = lit_model(X.cuda()).detach().cpu().numpy()\n",
    "    noise = estimate_noise(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877dc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic\n",
    "from utils.postprocessing import plot_pred_diagnostic\n",
    "\n",
    "\n",
    "\n",
    "i = np.argmin(noise.numpy().squeeze())\n",
    "#i = np.argmax(estimate_noise(Y).numpy().squeeze())\n",
    "# i = np.random.randint(len(X))\n",
    "#j = np.random.randint(n_dim)\n",
    "\n",
    "x = X[i,:,0].detach().cpu().numpy()\n",
    "y = Y[i,:,0].detach().cpu().numpy()\n",
    "mask = M[i,:,0].detach().cpu().numpy()\n",
    "info = {k:v[i].detach().cpu().item() for k,v in I.items()}\n",
    "y_pred = Y_pred[i,:,0]\n",
    "\n",
    "plot_pred_diagnostic(x, y, y_pred, mask=mask, targetid=info['targetid'], mu=info['mu'], sigma=info['sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fb916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### PLOT FOR ARTICLE\n",
    "# res = y - y_pred\n",
    "\n",
    "# f, ax = plt.subplots(1, 1, figsize=(17, 2))\n",
    "\n",
    "# # PREDICTION\n",
    "# ax.scatter(range(len(x)), y, label='input',\n",
    "#                  color='black', s=20, alpha=0.8)\n",
    "# if not np.isclose(x, y, equal_nan=True).all():\n",
    "#     ax.scatter(range(len(x)), y, label='target',\n",
    "#                      color='green', s=20, alpha=0.8)\n",
    "\n",
    "# if mask is not None:\n",
    "#     ymin, ymax = ax.get_ylim()\n",
    "#     ax.fill_between(range(len(x)), [ymin]*len(x), [ymax]\n",
    "#                           * len(x), where=mask, alpha=0.9, label='input mask')\n",
    "\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# ax.plot(y_pred, label='pred', color='red', alpha=1, lw=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print_cuda_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f213b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.stats import estimate_noise\n",
    "lit_model.eval().cuda()\n",
    "# lit_model.train()\n",
    "X, Y, M, I = next(iter(train_loader))\n",
    "Y_pred = lit_model(X.cuda())\n",
    "noise = estimate_noise(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_o = inverse_standardise_batch(Y, info['mu'], info['sigma'])\n",
    "pred_o = inverse_standardise_batch(Y_pred, info['mu'], info['sigma'])\n",
    "\n",
    "# Debugging nans\n",
    "nans = torch.isnan(y_o)\n",
    "m = M & ~nans\n",
    "y_o[nans] = 0.\n",
    "\n",
    "y_d = detrend(y_o, pred_o.cpu())\n",
    "#loss = self.criterion(torch.ones_like(y_d), y_d, m)  # x or y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardise_batch(x, mu, sigma):\n",
    "    return x * sigma + mu\n",
    "\n",
    "def detrend(x, trend):\n",
    "    return x / trend\n",
    "\n",
    "Y_o = inverse_standardise_batch(Y, I['mu'], I['sigma'])\n",
    "Y_pred_o = inverse_standardise_batch(Y_pred.cpu(), I['mu'], I['sigma'])\n",
    "\n",
    "Y_d = detrend(Y_o, Y_pred_o).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7262a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0])\n",
    "plt.show()\n",
    "plt.plot(Y[0])\n",
    "plt.plot(Y_pred[0].cpu().detach().numpy())\n",
    "plt.show()\n",
    "plt.plot(Y_o[0])\n",
    "plt.show()\n",
    "plt.plot(Y_d[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19831f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.loss import MaskedMSELoss\n",
    "\n",
    "loss = MaskedMSELoss()(torch.ones_like(Y_d), Y_d, mask=M)\n",
    "loss, torch.isnan(Y_d).sum(), torch.isnan(Y).sum(), torch.isinf(Y_d).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_d.detach().numpy()[:,:,0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52484c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbea1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import StandardScaler\n",
    "\n",
    "Y_pred_o = Y_pred.clone()\n",
    "\n",
    "Y_o = Y.clone()\n",
    "for k, i in enumerate(I['idx']):    \n",
    "    scaler = StandardScaler(dim=0)\n",
    "    scaler.fit(dataset[i][1]) ### What was used for preproc?? Careful to post transfos\n",
    "    Y_pred_o[k] = Y_pred[k] * scaler.norms.item() + scaler.centers.item()\n",
    "    Y_o[k] = scaler.inverse_transform(Y[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df417842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardise_batch(x, mu, sigma):\n",
    "    return x * sigma + mu\n",
    "\n",
    "def detrend(x, trend):\n",
    "    return x / trend\n",
    "\n",
    "Y_o = inverse_standardise_batch(Y, I['mu'], I['sigma'])\n",
    "Y_pred_o = inverse_standardise_batch(Y_pred.cpu(), I['mu'], I['sigma'])\n",
    "\n",
    "Y_d = detrend(Y_o, Y_pred_o).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_o.shape, Y_pred_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import nanstd\n",
    "\n",
    "noise2 = nanstd(Y_d, 1).numpy()\n",
    "plt.hist(noise2, 40)\n",
    "\n",
    "plt.show()\n",
    "plt.scatter(noise, noise2)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmin(noise2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, I['sigma'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_standardise_batch(x, mu, sigma):\n",
    "    return x * sigma + mu\n",
    "\n",
    "def detrend(x, trend):\n",
    "    return x / trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d901d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y_pred_o[:,:,0].cpu().detach().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_d = (Y_o / Y_pred_o.cpu())  # detrended\n",
    "\n",
    "plt.plot(Y_d[:,:,0].T.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ea11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[i][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.centers.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30583aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad15db99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a707dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22713b18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eaaa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.eval()#.cuda()\n",
    "X, Y, M, info = next(iter(val_loader))\n",
    "#X = X/2\n",
    "\n",
    "pred = lit_model(X, torch.zeros_like(X, dtype=bool)).detach()\n",
    "pred2 = pred.clone()\n",
    "i = np.random.randint(len(X))\n",
    "j = np.random.randint(n_dim)\n",
    "\n",
    "res = pred.cpu().detach()[i,:,j]-Y[i,:,j]\n",
    "res_m = res.clone()\n",
    "# res_nom = res.clone()\n",
    "\n",
    "res_m[~M[i,:,j]] = np.nan\n",
    "# res_nom[M[i,:,j]] = np.nan\n",
    "\n",
    "target = Y[i,:,j].clone()\n",
    "target_m = target.clone()\n",
    "# target_nom = target.clone()\n",
    "target_m[~M[i,:,j]] = np.nan\n",
    "# target_nom[M[i,:,j]] = np.nan\n",
    "\n",
    "\n",
    "pred = pred.cpu().detach()[i,:,j].clone()\n",
    "pred_m = pred.clone()\n",
    "# pred_nom = pred.clone()\n",
    "\n",
    "pred_m[~M[i,:,j]] = np.nan\n",
    "# pred_nom[M[i,:,j]] = np.nan\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "plt.scatter(range(len(X[i])), X[i,:,j], label='input', color='blue', s=3, alpha=0.4)\n",
    "\n",
    "plt.plot(target, label='target', color='green', alpha=0.7)\n",
    "#plt.scatter(range(len(res)), target_nom, color='green', alpha=0.7)\n",
    "plt.scatter(range(len\n",
    "                  (res)), target_m, marker=\"s\", color='green')\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(13,6))\n",
    "\n",
    "plt.plot(pred, label='pred', color='red', alpha=0.7)\n",
    "#plt.scatter(range(len(res)), pred_nom, color='red', alpha=0.7)\n",
    "plt.scatter(range(len(res)), pred_m, marker=\"s\", color='red')\n",
    "plt.show()\n",
    "plt.figure(figsize=(13,6))\n",
    "#plt.scatter(range(len(target)),  X[i,:,j], label='target', color='blue', alpha=0.7)\n",
    "\n",
    "\n",
    "plt.scatter(range(len(target)), target, label='target', color='green', alpha=0.7, s=5)\n",
    "plt.plot(pred, label='pred', color='red', alpha=0.7)\n",
    "plt.show()\n",
    "plt.figure(figsize=(13,6))\n",
    "\n",
    "# plt.scatter(range(len(res)), res_nom)\n",
    "plt.scatter(range(len(res)), res, color='blue')\n",
    "plt.scatter(range(len(res)), res_m, marker=\"s\", color='blue')\n",
    "\n",
    "#plt.plot(M[i,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.loss import \n",
    "\n",
    "def median_filter(x, width=10):\n",
    "    return pd.Series(x).rolling(width, center=True, min_periods=1).median().values\n",
    "\n",
    "def mean_filter(x, width=10):\n",
    "    return pd.Series(x).rolling(width, center=True, min_periods=1).mean().values\n",
    "\n",
    "\n",
    "pred_mean = dict()\n",
    "res_mean = dict()\n",
    "res_median = dict()\n",
    "\n",
    "pred_median = dict()\n",
    "for w in (10, 25, 40, 55):\n",
    "    pred_mean[w] = np.vstack([mean_filter(x[:,0], w) for x in X])\n",
    "    res_mean[w] = pred_mean[w] - Y[i,:,0].detach().numpy()\n",
    "    pred_median[w] = np.vstack([median_filter(x[:,0], w) for x in X])\n",
    "    res_median[w] = pred_median[w] - Y[i,:,0].detach().numpy()\n",
    "\n",
    "    # i = np.random.randint(len(Y))\n",
    "    # plt.plot(X[i])\n",
    "    # plt.plot(Y[i])\n",
    "    # plt.plot(pred[i])\n",
    "\n",
    "    mse_median = MaskedMSELoss()(torch.tensor(pred_median[w]), Y[:,:,0]).item()\n",
    "    mse_mean = MaskedMSELoss()(torch.tensor(pred_mean[w]), Y[:,:,0]).item()\n",
    "    print(f'\\twindow = {w}')\n",
    "    print(f'median filter : {mse_median:.4f}')\n",
    "    print(f'mean filter : {mse_mean:.4f}')\n",
    "\n",
    "mse_tst = MaskedMSELoss()(torch.tensor(pred2[:,:,0], device=\"cpu\"), Y[:,:,0]).item()\n",
    "print(f'\\nTransformer : {mse_tst:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897b63a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "plt.scatter(range(len(target)), target, label='target', color='green', alpha=0.7, s=5)\n",
    "#plt.plot(pred, label='Transformer', color='red', alpha=0.7)\n",
    "for w in pred_mean:\n",
    "    plt.plot(pred_mean[w][i], label=f'mean filter-{w}', alpha=0.7)\n",
    "\n",
    "plt.plot(pred, label='Transformer', lw=2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "for w in [40]:\n",
    "    plt.scatter(range(len(pred_mean[w][i])), \n",
    "                pred_mean[w][i]-Y[i,:,j].detach().numpy(), label=f'mean filter-{w}', alpha=0.7)\n",
    "#     plt.scatter(range(len(res)), res, color='blue')\n",
    "\n",
    "plt.scatter(range(len(res)), res, color='red')\n",
    "\n",
    "plt.scatter(range(len(res)), res_m, marker=\"s\", color='red', label='transfo')\n",
    "#     plt.scatter(range(len(res)), res_m, marker=\"s\", color='blue')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(res.numpy(), 50, range=(-3,3), label='transformer')\n",
    "plt.hist(res_mean[w][i], 50, range=(-3,3), label=f'mean filter-{w}', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8e486",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "plt.scatter(range(len(target)), target, label='target', color='green', alpha=0.7, s=5)\n",
    "#plt.plot(pred, label='Transformer', color='red', alpha=0.7)\n",
    "for w in pred_median:\n",
    "    plt.plot(pred_median[w][i], label=f'median filter-{w}', alpha=0.7)\n",
    "\n",
    "plt.plot(pred, label='Transformer')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13,6))\n",
    "for w in [40]:\n",
    "    plt.scatter(range(len(pred_median[w][i])), \n",
    "                pred_median[w][i]-Y[i,:,j].detach().numpy(), label=f'median filter-{w}', alpha=0.7)\n",
    "#     plt.scatter(range(len(res)), res, color='blue')\n",
    "\n",
    "\n",
    "plt.scatter(range(len(res)), res_m, marker=\"s\", color='red', label='transfo')\n",
    "#     plt.scatter(range(len(res)), res_m, marker=\"s\", color='blue')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(res.numpy(), 50, range=(-3,3), label='transformer')\n",
    "plt.hist(res_median[w][i], 50, range=(-3,3), label=f'median filter-{w}', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2594ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean[w].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf5cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808572f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511a1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce4b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff342a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57c9ae10",
   "metadata": {},
   "source": [
    "### Visualise attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57a7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477bd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0078d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # size study\n",
    "list_seq_len = [100, 200,  400, 700, 1000, 2000]\n",
    "# for L in list_seq_len:\n",
    "#     torch.cuda.empty_cache()\n",
    "#     lit_model = LitImputer(n_dim, d_model=64, dim_feedforward=128,  num_layers=3, eye=eye, lr=0.001,\n",
    "#                        normal_ratio=0.2, keep_ratio=0., token_ratio=0.8, attention='linear', seq_len=L\n",
    "#                       )\n",
    "    \n",
    "#     dataset.transform_both = Compose([RandomCrop(L),\n",
    "#                                       StandardScaler(dim=0),\n",
    "#                                      ])\n",
    "#     train_loader = DataLoader(dataset, batch_size=64, shuffle=True) \n",
    "\n",
    "#     trainer = pl.Trainer(max_epochs=3, \n",
    "#                          gpus=1, profiler='simple')\n",
    "\n",
    "#     result = trainer.fit(lit_model, \n",
    "#                          train_dataloaders=train_loader,                     \n",
    "#                          )\n",
    "\n",
    "# result_full = [0.16705 , 0.24147, 0.51497, np.nan, np.nan, np.nan] #B256\n",
    "result_full = [0.2 , 0.27, 0.54, 1.2, np.nan, np.nan] #B64\n",
    "# result_prob = [ 0.30687, 0.33286, 0.38871, 0.54279, 0.68638, 1.1525 ] #B256\n",
    "result_prob = [0.47, 0.48, 0.53, 0.64, 0.81, 1.3] #B64\n",
    "\n",
    "###result_lin = [0.25, 0.31, 0.46, 0.65, 0.87, 1.53] #B64\n",
    "result_lin = [0.21, 0.24, 0.32, 0.42, 0.52, 0.87]\n",
    "plt.plot(list_seq_len, result_full, marker='o', label='Full attention B64')#, marker='-o')\n",
    "plt.plot(list_seq_len, result_prob, marker='o', label='Prob attention B64')\n",
    "plt.plot(list_seq_len, result_lin, marker='o', label='Linformer attention B64')\n",
    "plt.legend()\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Training epoch time')\n",
    "print('batch size', train_loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163d417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fe60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c9ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ce906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1996c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4b010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e62655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180ce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b73d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9ae7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e1c08302b48d315bee1cf8c8a590d46ae916d527a5787d1c0b0275f91d47b8b"
  },
  "kernelspec": {
   "display_name": "Python [conda env:lct]",
   "language": "python",
   "name": "conda-env-lct-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
